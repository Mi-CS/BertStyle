{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../methods\")\n",
    "\n",
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Deep Learning\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Tokenize sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Utils\n",
    "from dataset_building import build_dataset\n",
    "from model import init_model\n",
    "from trainer import train_epoch\n",
    "\n",
    "# Measurements\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from classification import LogClassification, train_classifier\n",
    "from clustering import KMeansAuthors\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Here, as an example, we are taking a 3 author subset from the Reuters dataset just to simply show how the code works. For an actual training, proper training and test sets must be defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 31307.59it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 1133.37it/s]\n",
      "100%|██████████| 240/240 [00:04<00:00, 59.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_json(\"../data/reuters_sample.json\")\n",
    "\n",
    "# Clean and tokenize\n",
    "df.text = df.text.progress_apply(lambda x: x.lower())\n",
    "df.text = df.text.progress_apply(sent_tokenize)\n",
    "\n",
    "# Build dataset\n",
    "dataset = build_dataset(df.text,\n",
    "                masking_percentage=0.5,\n",
    "                max_pairs_per_doc = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = init_model(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # Construct DataLoader\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size = 16, \n",
    "                            shuffle = True)\n",
    "\n",
    "    train_epoch(model = model,\n",
    "                tokenizer = tokenizer,\n",
    "                dataloader = dataloader,\n",
    "                optimizer = optimizer,\n",
    "                criterion = criterion,\n",
    "                device = device,\n",
    "                print_each = 500, \n",
    "                disable_progress_bar = False)\n",
    "\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.isdir(\"saved_models\"):\n",
    "        os.mkdir(\"saved_models\")\n",
    "\n",
    "    # Save model weights after epoch\n",
    "    save_path = f\"saved_models/model_{epoch}epoch.pt\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(\"Model saved.\\n\\n\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style representations\n",
    "\n",
    "With the trained models, it is then easy to obtain the style representations for an input text. One simply needs to load the model, set it to the evaluation mode, and perform the forward pass for the given text(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = init_model(device)\n",
    "\n",
    "# Load trained model weights\n",
    "state = torch.load(f\"saved_models/saved_model.pt\", map_location=torch.device('cpu'))\n",
    "\n",
    "# This bit corrects the layer names in the saved PyTorch weights, so it can \n",
    "# match them. \n",
    "state_corrected = {key.replace(\"module.\", \"\"):value for key, value in state.items()}\n",
    "model.load_state_dict(state_corrected)\n",
    "\n",
    "# Set model to evaluation\n",
    "_ = model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_representations(sentence, tokenizer, model, device):\n",
    "    \"\"\"Simple method to obtain the style representation of a sentence\"\"\"\n",
    "\n",
    "    # Tokenize sentence\n",
    "    toks = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    tok_ids = toks.input_ids[:, :512]\n",
    "    att_mask = toks.attention_mask[:, :512]\n",
    "    tok_ids = tok_ids.to(device)\n",
    "    att_mask = att_mask.to(device)\n",
    "\n",
    "    # Forward pass, keeping only [CLS] from the last hidden state\n",
    "    out = model(tok_ids, att_mask, return_lhs=True)\n",
    "    return out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since for training we are using three sentences, we will\n",
    "# also use 3 sentences as input for evaluating our model\n",
    "def chunk_text(sent_list):\n",
    "    \"\"\"Group sentences into chunks of 3 sentences\"\"\"\n",
    "    total_length = len(sent_list)\n",
    "    chunks =  [sent_list[i:i+3] for i in \n",
    "                    range(0, total_length, 3)]\n",
    "\n",
    "    # Remove last chunk if it is too small\n",
    "    if len(chunks[-1]) != 3: \n",
    "        del chunks[-1]\n",
    "    \n",
    "    chunks = [\" \".join(chunk) for chunk in chunks]\n",
    "    return chunks\n",
    "\n",
    "df.text = df.text.apply(chunk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [08:17<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Build new column containing the style representations\n",
    "df[\"style_representations\"] = df.text.progress_apply(lambda sentences: \n",
    "                                np.vstack([get_style_representations(sent, tokenizer, model, device)\n",
    "                                                   for sent in sentences]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation methods\n",
    "\n",
    "## Method 1: Dimension reduction + K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "BenjaminKangLim       0.73      0.51      0.60        80\n",
      "    SamuelPerry       0.89      1.00      0.94        80\n",
      "   WilliamKazer       0.60      0.70      0.64        80\n",
      "\n",
      "       accuracy                           0.74       240\n",
      "      macro avg       0.74      0.74      0.73       240\n",
      "   weighted avg       0.74      0.74      0.73       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize data and apply PCA\n",
    "data = StandardScaler().fit_transform(np.vstack(df.style_representations))\n",
    "X = PCA(n_components=5).fit_transform(data)\n",
    "\n",
    "# Instantiate method\n",
    "cl = KMeansAuthors(n_authors=3)\n",
    "\n",
    "# Create an author label for each point\n",
    "auth_labels = [[author]*n_chunks for author, n_chunks in \n",
    "                zip(df.author, df.style_representations.apply(len))]\n",
    "\n",
    "# Flatten\n",
    "auth_labels = [x for y in auth_labels for x in y]\n",
    "\n",
    "# Fit data. Pass author labels to assign one author per cluster\n",
    "cl.fit(X, auth_labels)       \n",
    "\n",
    "# Metrics\n",
    "author_pred = cl.predict_document(X, df.style_representations.apply(len).to_numpy())\n",
    "print(classification_report(y_true = df.author, y_pred = author_pred, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier\n",
    "classifier = LogClassification(n_feat = len(df.style_representations[0][0]),\n",
    "                               n_class = len(df.author.unique()))\n",
    "\n",
    "# Create labels for authors\n",
    "auth_dict = dict(zip(set(df.author), range(len(df.author.unique()))))\n",
    "labels_train = [[auth_dict[auth]]*n_chunks for auth, n_chunks in zip(df.author,\n",
    " df.style_representations.apply(len))]\n",
    "\n",
    "# Flat labels and chunks \n",
    "labels_train = [x for y in labels_train for x in y]\n",
    "chunks = [x for chunk in df.style_representations for x in chunk]\n",
    "\n",
    "# Build dataset as tuples (chunk, label)\n",
    "dataset = list(zip(chunks, labels_train))\n",
    "\n",
    "# Just for the purpose of showing the code, we use \n",
    "# the dataframe we already have as also test set.\n",
    "df_test = df.copy()\n",
    "\n",
    "labels_test = [[auth_dict[auth]]*n_chunks for auth, n_chunks in zip(df_test.author,\n",
    " df_test.style_representations.apply(len))]\n",
    "\n",
    "# Flat labels and chunks \n",
    "labels_test = [x for y in labels_test for x in y]\n",
    "chunks = [x for chunk in df_test.style_representations for x in chunk]\n",
    "\n",
    "# Build dataset as tuples (chunk, label)\n",
    "dataset_test = list(zip(chunks, labels_test))\n",
    "\n",
    "# Normalize (if necessary) and build dataset\n",
    "scaler_train = StandardScaler().fit([x[0] for x in dataset])\n",
    "dataset = [(scaler_train.transform([x[0]])[0], x[1]) for x in dataset]\n",
    "dataset_test = [(scaler_train.transform([x[0]])[0], x[1]) for x in dataset_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "# Train  classifier and generate json files with results\n",
    "train_classifier(classifier, \n",
    "                 dataset, \n",
    "                 dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch 0</th>\n",
       "      <th>Epoch 1</th>\n",
       "      <th>Epoch 2</th>\n",
       "      <th>Epoch 3</th>\n",
       "      <th>Epoch 4</th>\n",
       "      <th>Epoch 5</th>\n",
       "      <th>Epoch 6</th>\n",
       "      <th>Epoch 7</th>\n",
       "      <th>Epoch 8</th>\n",
       "      <th>Epoch 9</th>\n",
       "      <th>Epoch 10</th>\n",
       "      <th>Epoch 11</th>\n",
       "      <th>Epoch 12</th>\n",
       "      <th>Epoch 13</th>\n",
       "      <th>Epoch 14</th>\n",
       "      <th>Epoch 15</th>\n",
       "      <th>Epoch 16</th>\n",
       "      <th>Epoch 17</th>\n",
       "      <th>Epoch 18</th>\n",
       "      <th>Epoch 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>85.497150</td>\n",
       "      <td>89.867004</td>\n",
       "      <td>91.196960</td>\n",
       "      <td>92.336922</td>\n",
       "      <td>93.476884</td>\n",
       "      <td>93.033566</td>\n",
       "      <td>94.300190</td>\n",
       "      <td>94.300190</td>\n",
       "      <td>94.300190</td>\n",
       "      <td>95.123496</td>\n",
       "      <td>95.630146</td>\n",
       "      <td>95.693477</td>\n",
       "      <td>96.136795</td>\n",
       "      <td>96.010133</td>\n",
       "      <td>96.580114</td>\n",
       "      <td>96.706776</td>\n",
       "      <td>96.833439</td>\n",
       "      <td>96.453452</td>\n",
       "      <td>96.833439</td>\n",
       "      <td>97.340089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.855471</td>\n",
       "      <td>0.898889</td>\n",
       "      <td>0.912537</td>\n",
       "      <td>0.923483</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.930888</td>\n",
       "      <td>0.943434</td>\n",
       "      <td>0.943422</td>\n",
       "      <td>0.943492</td>\n",
       "      <td>0.951776</td>\n",
       "      <td>0.956736</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.961878</td>\n",
       "      <td>0.960602</td>\n",
       "      <td>0.966249</td>\n",
       "      <td>0.967454</td>\n",
       "      <td>0.968762</td>\n",
       "      <td>0.964941</td>\n",
       "      <td>0.968735</td>\n",
       "      <td>0.973732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Epoch 0    Epoch 1    Epoch 2    Epoch 3    Epoch 4    Epoch 5  \\\n",
       "Accuracy  85.497150  89.867004  91.196960  92.336922  93.476884  93.033566   \n",
       "F1_score   0.855471   0.898889   0.912537   0.923483   0.935147   0.930888   \n",
       "\n",
       "            Epoch 6    Epoch 7    Epoch 8    Epoch 9   Epoch 10   Epoch 11  \\\n",
       "Accuracy  94.300190  94.300190  94.300190  95.123496  95.630146  95.693477   \n",
       "F1_score   0.943434   0.943422   0.943492   0.951776   0.956736   0.957449   \n",
       "\n",
       "           Epoch 12   Epoch 13   Epoch 14   Epoch 15   Epoch 16   Epoch 17  \\\n",
       "Accuracy  96.136795  96.010133  96.580114  96.706776  96.833439  96.453452   \n",
       "F1_score   0.961878   0.960602   0.966249   0.967454   0.968762   0.964941   \n",
       "\n",
       "           Epoch 18   Epoch 19  \n",
       "Accuracy  96.833439  97.340089  \n",
       "F1_score   0.968735   0.973732  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check measurements\n",
    "pd.read_json(\"training_measurements.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acd62c5062357039a923d5a2091962054c169ae848350ae1587a2a7c600dc804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
